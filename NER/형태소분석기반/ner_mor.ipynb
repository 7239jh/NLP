{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('./data/train.tsv',sep='\\t')\n",
    "dft=df['text'].tolist()\n",
    "\n",
    "with open('./data/exam.txt', \"w\", encoding='utf-8') as f:\n",
    "    for d in dft:\n",
    "        line=''\n",
    "        line=line+d\n",
    "        f.write('{}\\n'.format(line.strip()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 유니그램, 바이그램 자모분해"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni=[]\n",
    "bi=[]\n",
    "with open('./data/exam.txt', \"r\", encoding='utf-8') as infile:\n",
    "    for line in infile:\n",
    "        a=line.split()\n",
    "        for i in a:\n",
    "            uni.append(i)\n",
    "        for i in range(len(a)-1):\n",
    "            b=a[i]+\" \"+a[i+1]\n",
    "            bi.append(b)\n",
    "            \n",
    "from collections import Counter\n",
    "uni_c=Counter(uni).most_common(n=100)\n",
    "bi_c=Counter(bi).most_common(n=100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/dict_uni.txt', \"w\", encoding='utf-8') as f:\n",
    "    for d in uni_c:\n",
    "        line=''\n",
    "        line=line+d[0]+\" \"+str(d[1])\n",
    "        f.write('{}\\n'.format(line.strip()))\n",
    "        \n",
    "with open('./data/dict_bi.txt', \"w\", encoding='utf-8') as f:\n",
    "    for d in bi_c:\n",
    "        line=''\n",
    "        line=line+d[0]+\" \"+str(d[1])\n",
    "        f.write('{}\\n'.format(line.strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jamo import h2j, j2hcj\n",
    "with open('./data/dict_uni_d.txt', \"w\", encoding='utf-8') as f:\n",
    "    for d in uni_c:\n",
    "        line=''\n",
    "        line=line+j2hcj(h2j(d[0]))+\" \"+str(d[1])\n",
    "        f.write('{}\\n'.format(line.strip()))\n",
    "\n",
    "with open('./data/dict_bi_d.txt', \"w\", encoding='utf-8') as f:\n",
    "    for d in bi_c:\n",
    "        line=''\n",
    "        line=line+j2hcj(h2j(d[0]))+\" \"+str(d[1])\n",
    "        f.write('{}\\n'.format(line.strip()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 오타보정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from symspellpy_ko_master.symspellpy_ko import KoSymSpell, Verbosity\n",
    "\n",
    "sym_spell = KoSymSpell()\n",
    "sym_spell.load_korean_dictionary(decompose_korean=True, load_bigrams=True) # symspell.py에서 딕셔너리 파일 명 바꿔주자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "삼성젼자쥬가 올마야  >>>  삼성전자 주가 얼마야\n",
      "듀산애너빌리티 시새는?  >>>  두산에너빌리티 시세는?\n",
      "LG 우 종가는?  >>>  LG우 종가는?\n"
     ]
    }
   ],
   "source": [
    "text1 = \"삼성젼자쥬가 올마야\"\n",
    "text2=\"듀산애너빌리티 시새는?\"\n",
    "text3=\"LG 우 종가는?\"\n",
    "\n",
    "for suggestion in sym_spell.lookup_compound(text1, max_edit_distance=2):\n",
    "    a=suggestion.term\n",
    "    print(text1+'  >>>  '+a)\n",
    "for suggestion in sym_spell.lookup_compound(text2, max_edit_distance=2):\n",
    "    b=suggestion.term\n",
    "    print(text2+'  >>>  '+b)\n",
    "for suggestion in sym_spell.lookup_compound(text3, max_edit_distance=2):\n",
    "    c=suggestion.term\n",
    "    print(text3+'  >>>  '+c)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 엔티티 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'삼성전자': 'st',\n",
       " '두산에너빌리티': 'st',\n",
       " 'LG우': 'st',\n",
       " '주가': 'pr',\n",
       " '시세': 'pr',\n",
       " '종가': 'pr'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key=['삼성전자','두산에너빌리티','LG우','주가','시세','종가']\n",
    "value=['st','st','st','pr','pr','pr']\n",
    "dict_ner=dict(zip(key,value))\n",
    "dict_ner"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 오타 보정 후 ner분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "삼성젼자쥬가 올마야   >>>   삼성전자 주가 얼마야   >>>   Intent: [('삼성전자', 'st'), ('주가', 'pr')]\n",
      "듀산애너빌리티 시새는?   >>>   두산에너빌리티 시세는?   >>>   Intent: [('두산에너빌리티', 'st'), ('시세', 'pr')]\n",
      "LG 우 종가는?   >>>   LG우 종가는?   >>>   Intent: [('종가', 'pr')]\n"
     ]
    }
   ],
   "source": [
    "import konlpy\n",
    "from konlpy.tag import Komoran\n",
    "komoran = Komoran(userdic='my_dict.txt') # 코모란 사전 이걸로 교체\n",
    "words1 = komoran.pos(a)\n",
    "words2 = komoran.pos(b)\n",
    "words3 = komoran.pos(c)\n",
    "nouns1=[w[0] for w in words1 if ('NNG' in w or 'NNP' in w)]\n",
    "nouns2=[w[0] for w in words2 if ('NNG' in w or 'NNP' in w)]\n",
    "nouns3=[w[0] for w in words3 if ('NNG' in w or 'NNP' in w)]\n",
    "ner1=[(i,dict_ner[i]) for i in nouns1 if (i in dict_ner)]\n",
    "ner2=[(i,dict_ner[i]) for i in nouns2 if (i in dict_ner)]\n",
    "ner3=[(i,dict_ner[i]) for i in nouns3 if (i in dict_ner)]\n",
    "print(text1,'  >>>  ',a,'  >>>  ','Intent:',ner1)\n",
    "print(text2,'  >>>  ',b,'  >>>  ','Intent:',ner2)\n",
    "print(text3,'  >>>  ',c,'  >>>  ','Intent:',ner3)  # LG우 는 정식 종목명이 아니라 형태소 사전에 없음 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base_jupyter",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "59c86215cb6667c49c42aaf9f4968b164f63cbe3d18b8d322d177a685e6eefb7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
